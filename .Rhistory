if (is.na(page_name) || page_name == "") {
return("No Wikipedia page name provided or missing.")
}
# Try fetching Wikipedia content
tryCatch({
wp_content <- WikipediR::page_content("de", "wikipedia", page_name = page_name)
plain_text <- html_text(read_html(wp_content$parse$text$`*`))
return(plain_text)
}, error = function(e) {
return(paste("Error fetching content for page:", page_name))
})
}
de_text_pipeline <- function(page_name) {
Sys.sleep(runif(1, 1, 2))
# Check if page_name is missing
if (is.na(page_name) || page_name == "") {
return("No Wikipedia page name provided or missing.")
}
# Try fetching Wikipedia content
tryCatch({
wp_content <- WikipediR::page_content("de", "wikipedia", page_name = page_name)
plain_text <- html_text(read_html(wp_content$parse$text$`*`))
return(plain_text)
}, error = function(e) {
return(paste("Error fetching content for page:", page_name))
})
}
deu_alive_text <- deu_core %>%
mutate(plain_text = sapply(wikititle, de_text_pipeline))
library(legislatoR)
library(WikipediR)
library(rvest)
library(dplyr)
deu_core <- get_core(legislature = "deu")
de_text_pipeline <- function(page_name) {
Sys.sleep(runif(1, 1, 2))
# Check if page_name is missing
if (is.na(page_name) || page_name == "") {
return("No Wikipedia page name provided or missing.")
}
# Try fetching Wikipedia content
tryCatch({
wp_content <- WikipediR::page_content("de", "wikipedia", page_name = page_name)
plain_text <- html_text(read_html(wp_content$parse$text$`*`))
return(plain_text)
}, error = function(e) {
return(paste("Error fetching content for page:", page_name))
})
}
deu_text <- deu_core %>%
mutate(plain_text = sapply(wikititle, de_text_pipeline))
View(deu_text)
#save
write.csv(deu_text, file = "raw_data/deu_text.csv", row.names = FALSE)
#save
write.csv(deu_text, file = "raw_data/deu_text.csv", row.names = FALSE)
setwd("~/Documents/Zukunft/Master/drittes semester/thesis/Code/Thesis")
#save
write.csv(deu_text, file = "raw_data/deu_text.csv", row.names = FALSE)
library(legislatoR)
library(WikipediR)
library(rvest)
library(dplyr)
library(stringr) #für word count
library(ggplot2)
clean_data <- function(df) {
initial_rows <- nrow(df)
# Remove CSS-like structures
df$plain_text <- str_remove_all(df$plain_text, "\\..*?\\{.*?\\}")
# Initialize counters for removal reasons
removal_reason_redirect <- sum(grepl("^(Redirect to:|Weiterleitung nach:|Rediriger vers:|Redirige a:|Přesměrování na:)", df$plain_text, ignore.case = TRUE))
removal_reason_refering_page <- sum(grepl("may refer to:|ist der Name folgender Personen:|Cette page d'homonymie répertorie différentes personnes|může být:", df$plain_text, ignore.case = TRUE))
removal_reason_not_found <- sum(grepl("^(Error fetching content for page:|No Wikipedia page name provided or missing|Es wurde kein Wikipedia-Seitenname angegeben)", df$plain_text, ignore.case = TRUE))
# Filter rows based on specific conditions
df <- df %>%
filter(!grepl("^(Redirect to:|Weiterleitung nach:|Rediriger vers:|Redirige a:|Přesměrování na:)", plain_text, ignore.case = TRUE) &
!grepl("may refer to:|ist der Name folgender Personen:|Cette page d'homonymie répertorie différentes personnes|může být:", plain_text, ignore.case = TRUE) &
!grepl("Error fetching content for page:|No Wikipedia page name provided or missing|Es wurde kein Wikipedia-Seitenname angegeben", plain_text, ignore.case = TRUE))
# Calculate the number of rows removed
rows_removed <- initial_rows - nrow(df)
# Print statistics about the removal reasons
cat("Removal reasons:\n")
cat("  - Redirect:", removal_reason_redirect, "\n")
cat("  - Reference Page:", removal_reason_refering_page, "\n")
cat("  - Not Found/no name_provided:", removal_reason_not_found, "\n")
# Create a message about the cleaning process
cat("Cleaned data: Removed", rows_removed, "rows.\n")
# Return the cleaned data frame
return(df)
}
deu <- clean_data(deu_text)
library(MatchIt)
install.packages("MatchIt")
library(MatchIt)
View(deu)
birthyear <- substring(deu$birth, 1, 4)
deu$birthyear <- substr(deu$birth, 1, 4)
View(deu)
#Using the mathcit function from MatchIt to match each smoker with a non-smoker (1 to 1 matching) based on
#sex, indigeneity status, high school completion, marital status (partnered or not),
#region of residence (major cities, inner regional, outer regional), language background (English speaking Yes/No)
#and risky alcohol drinking (Yes/No)
match_obj <- matchit(sex ~ religion + ethnicity + birthyear,
data = deu, method = "nearest", distance ="glm",
ratio = 1,
replace = FALSE)
#Using the mathcit function from MatchIt to match each smoker with a non-smoker (1 to 1 matching) based on
#sex, indigeneity status, high school completion, marital status (partnered or not),
#region of residence (major cities, inner regional, outer regional), language background (English speaking Yes/No)
#and risky alcohol drinking (Yes/No)
match_obj <- matchit(sex ~ religion + ethnicity,
data = deu, method = "nearest", distance ="glm",
ratio = 1,
replace = FALSE)
#Using the mathcit function from MatchIt to match each smoker with a non-smoker (1 to 1 matching) based on
#sex, indigeneity status, high school completion, marital status (partnered or not),
#region of residence (major cities, inner regional, outer regional), language background (English speaking Yes/No)
#and risky alcohol drinking (Yes/No)
match_obj <- matchit(sex ~ religion,
data = deu, method = "nearest", distance ="glm",
ratio = 1,
replace = FALSE)
#Using the mathcit function from MatchIt to match each smoker with a non-smoker (1 to 1 matching) based on
#sex, indigeneity status, high school completion, marital status (partnered or not),
#region of residence (major cities, inner regional, outer regional), language background (English speaking Yes/No)
#and risky alcohol drinking (Yes/No)
match_obj <- matchit(sex ~ birthyear,
data = deu, method = "nearest", distance ="glm",
ratio = 1,
replace = FALSE)
deu <- na.omit(deu$sex)
deu <- clean_data(deu_text)
deu$birthyear <- substr(deu$birth, 1, 4)
deu <- deu[complete.cases(deu$sex), ]
#Using the mathcit function from MatchIt to match each smoker with a non-smoker (1 to 1 matching) based on
#sex, indigeneity status, high school completion, marital status (partnered or not),
#region of residence (major cities, inner regional, outer regional), language background (English speaking Yes/No)
#and risky alcohol drinking (Yes/No)
match_obj <- matchit(sex ~ birthyear + religion + ethnicity,
data = deu, method = "nearest", distance ="glm",
ratio = 1,
replace = FALSE)
missing_share <- colMeans(is.na(deu))
print(missing_share)
deu <- deu[complete.cases(deu), ]
#Using the mathcit function from MatchIt to match each smoker with a non-smoker (1 to 1 matching) based on
#sex, indigeneity status, high school completion, marital status (partnered or not),
#region of residence (major cities, inner regional, outer regional), language background (English speaking Yes/No)
#and risky alcohol drinking (Yes/No)
match_obj <- matchit(sex ~ birthyear + religion + ethnicity,
data = deu, method = "nearest", distance ="glm",
ratio = 1,
replace = FALSE)
levels(deu$religion)
levels(deu$ethnicity)
View(deu)
deu <- clean_data(deu_text)
deu$birthyear <- substr(deu$birth, 1, 4)
deu <- deu[complete.cases(deu$sex), ]
deu_imputed <- apply(deu, 2, function(x) {
if(is.factor(x)) {
x[is.na(x)] <- levels(x)[which.max(table(x))]
} else {
x[is.na(x)] <- median(x, na.rm = TRUE)
}
return(x)
})
View(deu)
deu$religion[is.na(deu$religion)] <- levels(deu$religion)[which.max(table(deu$religion))]
deu$religion[is.na(deu$religion)] <- "Unknown"
deu$ethnicity[is.na(deu$ethnicity)] <- "Unknown"
missing_share <- colMeans(is.na(deu))
print(missing_share)
#Using the mathcit function from MatchIt to match each smoker with a non-smoker (1 to 1 matching) based on
#sex, indigeneity status, high school completion, marital status (partnered or not),
#region of residence (major cities, inner regional, outer regional), language background (English speaking Yes/No)
#and risky alcohol drinking (Yes/No)
match_obj <- matchit(sex ~ birthyear + religion + ethnicity,
data = deu, method = "nearest", distance ="glm",
ratio = 1,
replace = FALSE)
unique(deu$sex)
#binary
deu$sex <- ifelse(deu$sex == "male", 0, 1)
#Using the mathcit function from MatchIt to match each smoker with a non-smoker (1 to 1 matching) based on
#sex, indigeneity status, high school completion, marital status (partnered or not),
#region of residence (major cities, inner regional, outer regional), language background (English speaking Yes/No)
#and risky alcohol drinking (Yes/No)
match_obj <- matchit(sex ~ birthyear + religion + ethnicity,
data = deu, method = "nearest", distance ="glm",
ratio = 1,
replace = FALSE)
View(match_obj)
summary(match_obj)
matched_data <- match.data(match_obj)
View(matched_data)
View(matched_data)
summary(matched_data)
?legislatoR()
deu_political <- get_political(legislature = "deu")
View(deu_political)
missing_share <- colMeans(is.na(deu))
print(missing_share)
View(matched_data)
#tokenize
corpus <- Corpus(VectorSource(matched_data$plain_text))
#tokenize
library(tm)
corpus <- Corpus(VectorSource(matched_data$plain_text))
View(corpus)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("german"))
corpus <- tm_map(corpus, stemDocument)
dtm <- DocumentTermMatrix(corpus)
View(dtm)
word_counts <- rowSums(as.matrix(dtm))
#create the vocabulary, containing “gender”, “word” and “Number of biographies”
vocabulary <- data.frame(
gender = df$gender,
word = colnames(dtm),
count = word_counts
)
#create the vocabulary, containing “gender”, “word” and “Number of biographies”
vocabulary <- data.frame(
gender = df$sex,
word = colnames(dtm),
count = word_counts
)
#create the vocabulary, containing “gender”, “word” and “Number of biographies”
vocabulary <- data.frame(
gender = matched_data$sex,
word = colnames(dtm),
count = word_counts
)
dtm_matrix <- as.matrix(dtm)
num_words <- nrow(dtm_matrix)
num_docs <- ncol(dtm_matrix)
word_counts_male <- data.frame(word = character(), count_male = integer(), stringsAsFactors = FALSE)
word_counts_female <- data.frame(word = character(), count_female = integer(), stringsAsFactors = FALSE)
for (i in 1:num_words) {
word <- rownames(dtm_matrix)[i]
counts <- colSums(dtm_matrix[i, ])
# Count occurrences of the word for males and females separately
count_male <- sum(counts[matched_data$sex == "male"])
count_female <- sum(counts[matched_data$sex == "female"])
# Append the word counts to the data frames
word_counts_male <- rbind(word_counts_male, data.frame(word = word, count_male = count_male))
word_counts_female <- rbind(word_counts_female, data.frame(word = word, count_female = count_female))
}
View(matched_data)
for (i in 1:num_words) {
word <- rownames(dtm_matrix)[i]
counts <- colSums(dtm_matrix[i, ])
# Count occurrences of the word for males and females separately
count_male <- sum(counts[matched_data$sex == "1"])
count_female <- sum(counts[matched_data$sex == "0"])
# Append the word counts to the data frames
word_counts_male <- rbind(word_counts_male, data.frame(word = word, count_male = count_male))
word_counts_female <- rbind(word_counts_female, data.frame(word = word, count_female = count_female))
}
library(tidyverse)
library(tokenizers)
vocabulary <- list(male = list(), female = list())
for (i in 1:nrow(matched_data)) {
gender <- df$sex[i]
text <- df$text[i]
# Tokenize the text into words
words <- unlist(tokenize_words(text))
# Update the vocabulary dictionary
vocabulary[[gender]] <- union(vocabulary[[gender]], words)
}
for (i in 1:nrow(matched_data)) {
gender <- matched_data$sex[i]
text <- matched_data$plain_text[i]
# Tokenize the text into words
words <- unlist(tokenize_words(plain_text))
# Update the vocabulary dictionary
vocabulary[[gender]] <- union(vocabulary[[gender]], words)
}
View(matched_data)
View(matched_data)
for (i in 1:nrow(matched_data)) {
gender <- matched_data$sex[i]
text <- matched_data$plain_text[i]
# Tokenize the text into words
words <- unlist(tokenize_words(text))
# Update the vocabulary dictionary
vocabulary[[gender]] <- union(vocabulary[[gender]], words)
}
for (i in 1:nrow(matched_data)) {
gender <- matched_data$sex[i]
text <- matched_data$plain_text[i]
# Tokenize the text into words
words <- unlist(tokenize_words(text))
# Debugging statements
cat("Gender:", gender, "\n")
cat("Text:", text, "\n")
cat("Words:", words, "\n")
# Update the vocabulary dictionary
vocabulary[[gender]] <- union(vocabulary[[gender]], words)
}
for (i in 1:nrow(matched_data)) {
gender <- ifelse(matched_data$gender[i] == 0, "female", "male")
text <- matched_data$plain_text[i]
# Tokenize the text into words
words <- unlist(tokenize_words(text))
# Debugging statements
cat("Gender:", gender, "\n")
cat("Text:", text, "\n")
cat("Words:", words, "\n")
# Update the vocabulary dictionary
vocabulary[[gender]] <- union(vocabulary[[gender]], words)
}
for (i in 1:nrow(matched_data)) {
gender <- ifelse(matched_data$sex[i] == 1, "female", "male")
text <- matched_data$plain_text[i]
# Tokenize the text into words
words <- unlist(tokenize_words(text))
# Debugging statements
cat("Gender:", gender, "\n")
cat("Text:", text, "\n")
cat("Words:", words, "\n")
# Update the vocabulary dictionary
vocabulary[[gender]] <- union(vocabulary[[gender]], words)
}
test <- head(matched_data,20)
View(test)
for (i in 1:nrow(test)) {
gender <- ifelse(test$sex[i] == 1, "female", "male")
text <- test$plain_text[i]
# Tokenize the text into words
words <- unlist(tokenize_words(text))
# Debugging statements
cat("Gender:", gender, "\n")
cat("Text:", text, "\n")
cat("Words:", words, "\n")
# Update the vocabulary dictionary
vocabulary[[gender]] <- union(vocabulary[[gender]], words)
}
print(vocabulary)
anzahl_frauen <- length(vocabulary$female)
anzahl_maenner <- length(vocabulary$male)
haufigstes_wort_frauen <- names(sort(vocabulary$female, decreasing = TRUE)[1])
vorkommen_frauen <- sapply(vocabulary$female, length)
# Das Wort mit den meisten Vorkommen für Frauen finden
haufigstes_wort_frauen <- names(vorkommen_frauen)[which.max(vorkommen_frauen)]
# Anzeigen des am häufigsten verwendeten Wortes für Frauen
print(paste("Am häufigsten verwendetes Wort für Frauen:", haufigstes_wort_frauen))
length_female <- length(vocabulary$female)
male_dataset <- matched_data %>% filter(sex == "0")
female_dataset <- matched_data %>% filter(sex == "1")
female_corpus <- Corpus(VectorSource(female_dataset$text))
View(corpus)
View(female_corpus)
female_corpus <- Corpus(VectorSource(female_dataset$text))
View(female_corpus)
View(female_corpus)
View(female_dataset)
female_corpus <- Corpus(VectorSource(female_dataset$plain_text))
View(female_corpus)
female_corpus <- tm_map(female_corpus, content_transformer(tolower))
View(female_corpus)
View(female_dataset)
female_corpus <- tm_map(female_corpus, removePunctuation)
female_corpus <- tm_map(female_corpus, removeNumbers)
female_corpus <- tm_map(female_corpus, removeWords, stopwords("german"))
female_corpus <- tm_map(female_corpus, stripWhitespace)
View(female_corpus)
female_corpus <- tm_map(female_corpus, stemDocument)
View(female_corpus)
# Optional: Anzeigen der ersten paar Dokumente im Corpus
inspect(corpus[1:5])
tdm <- TermDocumentMatrix(female_corpus)
m <- as.matrix(tdm)
View(tdm)
View(m)
word_counts <- rowSums(m)
vocabulary <- data.frame(word = names(word_counts), count = word_counts)
View(vocabulary)
male_corpus <- Corpus(VectorSource(male_dataset$plain_text))
View(male_corpus)
male_corpus <- tm_map(male_corpus, content_transformer(tolower))
male_corpus <- tm_map(male_corpus, removePunctuation)
male_corpus <- tm_map(male_corpus, removeNumbers)
male_corpus <- tm_map(male_corpus, removeWords, stopwords("german"))
male_corpus <- tm_map(male_corpus, stripWhitespace)
male_corpus <- tm_map(male_corpus, stemDocument)
inspect(male_corpus[1:5])
male_tdm <- TermDocumentMatrix(male_corpus)
male_m <- as.matrix(male_tdm)
male_word_counts <- rowSums(male_m)
male_vocabulary <- data.frame(word = names(male_word_counts), count = male_word_counts)
View(male_vocabulary)
wp_content <- page_content("en","wikipedia", page_name = "Aaron Halfaker")
View(wp_content)
wp_content[["parse"]][["text"]][["*"]]
html_doc <- read_html(wp_content[["parse"]][["text"]][["*"]])
View(html_doc)
View(male_vocabulary)
str(male_vocabulary)
View(word_counts_female)
View(male_vocabulary)
male_vocabulary <- data.frame(word = names(count = male_word_counts)
male_vocabulary <- data.frame(word = names(count = male_word_counts)
View(male_vocabulary)
male_vocabulary <- data.frame(word = names(count = male_word_counts))
rownames(male_word_counts) <- NULL
male_vocabulary <- data.frame(word = names(male_word_counts), count = male_word_counts)
View(male_vocabulary)
male_corpus <- Corpus(VectorSource(male_dataset$plain_text))
male_corpus <- tm_map(male_corpus, content_transformer(tolower))
male_corpus <- tm_map(male_corpus, removePunctuation)
male_corpus <- tm_map(male_corpus, removeNumbers)
male_corpus <- tm_map(male_corpus, removeWords, stopwords("german"))
male_corpus <- tm_map(male_corpus, stripWhitespace)
male_corpus <- tm_map(male_corpus, stemDocument)
inspect(male_corpus[1:5])
male_tdm <- TermDocumentMatrix(male_corpus)
male_m <- as.matrix(male_tdm)
male_word_counts <- rowSums(male_m)
rownames(male_word_counts) <- NULL
male_vocabulary <- data.frame(word = names(male_word_counts), count = male_word_counts)
View(male_vocabulary)
rownames(male_word_counts) <- NULL
View(male_vocabulary)
male_vocabulary <- data.frame(word = names(male_word_counts), count = male_word_counts)
View(male_vocabulary)
male_word_counts <- as.vector(male_word_counts)
# Create the dataframe without row names
male_vocabulary <- data.frame(word = names(male_word_counts), count = male_word_counts)
View(male_corpus)
View(male_m)
male_word_counts
male_vocabulary <- data.frame(word = names(male_word_counts), count = male_word_counts)
View(word_counts_female)
##html text
de_html_pipeline <- function(page_name) {
Sys.sleep(runif(1, 1, 2))
# Check if page_name is missing
if (is.na(page_name) || page_name == "") {
return("No Wikipedia page name provided or missing.")
}
# Try fetching Wikipedia content
tryCatch({
wp_content <- WikipediR::page_content("de", "wikipedia", page_name = page_name)
plain_text <- read_html(wp_content$parse$text$`*`)
return(text)
}, error = function(e) {
return(paste("Error fetching content for page:", page_name))
})
}
de_html_pipeline("Aaron Halfaker")
de_text_pipeline <- function(page_name) {
Sys.sleep(runif(1, 1, 2))
# Überprüfen, ob page_name fehlt
if (is.na(page_name) || page_name == "") {
return("Kein Wikipedia-Seitenname angegeben oder fehlend.")
}
# Versuchen, Wikipedia-Inhalt abzurufen
tryCatch({
wp_content <- WikipediR::page_content("de", "wikipedia", page_name = page_name)
html_content <- wp_content$parse$text$`*`
return(html_content)
}, error = function(e) {
return(paste("Fehler beim Abrufen des Inhalts für die Seite:", page_name))
})
}
##html text
de_html_pipeline <- function(page_name) {
Sys.sleep(runif(1, 1, 2))
# Überprüfen, ob page_name fehlt
if (is.na(page_name) || page_name == "") {
return("Kein Wikipedia-Seitenname angegeben oder fehlend.")
}
# Versuchen, Wikipedia-Inhalt abzurufen
tryCatch({
wp_content <- WikipediR::page_content("de", "wikipedia", page_name = page_name)
html_content <- wp_content$parse$text$`*`
return(html_content)
}, error = function(e) {
return(paste("Fehler beim Abrufen des Inhalts für die Seite:", page_name))
})
}
de_html_pipeline("Aaron Halfaker")
deu_html_text <- deu_core %>%
mutate(text = sapply(wikititle, de_html_pipeline))
library(legislatoR)
library(WikipediR)
library(rvest)
library(dplyr)
library(stringr) #für word count
library(ggplot2)
##html text
de_html_pipeline <- function(page_name) {
Sys.sleep(runif(1, 1, 2))
# Überprüfen, ob page_name fehlt
if (is.na(page_name) || page_name == "") {
return("Kein Wikipedia-Seitenname angegeben oder fehlend.")
}
# Versuchen, Wikipedia-Inhalt abzurufen
tryCatch({
wp_content <- WikipediR::page_content("de", "wikipedia", page_name = page_name)
html_content <- wp_content$parse$text$`*`
return(html_content)
}, error = function(e) {
return(paste("Fehler beim Abrufen des Inhalts für die Seite:", page_name))
})
}
deu_html_text <- deu_core %>%
mutate(text = sapply(wikititle, de_html_pipeline))
