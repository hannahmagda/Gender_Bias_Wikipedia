---
title: "PMI_de"
author: "Hannah Schweren"
date: "2024-02-22"
output: html_document
---
```{r}
library(legislatoR)
library(WikipediR)
library(rvest)
library(dplyr)
library(stringr) #für word count
library(ggplot2)
library(tm)
library(MatchIt)
library(quanteda)
library(purrr)


```

Read in Data
```{r}
setwd("~/Documents/Zukunft/Master/drittes semester/thesis/code")

deu_political <- read.csv("deu_political.csv")
deu_traffic <- read.csv("deu_traffic.csv")
deu_text <- read.csv("deu_text.csv")

```

```{r}
#doppelte sessions: nur älteste behalten und service aufaddieren
deu_political <- deu_political %>%
  group_by(pageid) %>%
  mutate(
    total_service = if (n() > 1) sum(service, na.rm = TRUE) else if_else(!is.na(service), service, 0)
  ) %>%
  slice(which.min(session)) %>%
  ungroup()


#sum of traffic data per politician
total_traffic_per_politician <- deu_traffic %>%
  group_by(pageid) %>%
  summarise(total_traffic = sum(traffic))

```


```{r}
# funtion für leben text selection
extract_content <- function(text) {
  tryCatch({
    parts <- str_split(text, "\\[Bearbeiten \\| Quelltext bearbeiten\\]")[[1]]
    
    if (length(parts) >= 3) {
      content_between = parts[2]
      paragraph_positions <- str_locate_all(content_between, "\n\n")[[1]][,1]
      
      if (length(paragraph_positions) > 0) {
        last_paragraph_pos <- max(paragraph_positions, na.rm = TRUE)
        return(substr(content_between, 1, last_paragraph_pos))
      } else {
        return(content_between)
      }
    } else {
      return(NA)
    }
  }, error = function(e) { 
    NA 
  })
}

deu_text <- deu_text %>%
  mutate(extracted_text = map_chr(plain_text, possibly(extract_content, otherwise = NA_character_)))

```

```{r}
clean_data <- function(df) {
  initial_rows <- nrow(df)
  
  # Remove CSS-like structures
  #df$plain_text <- str_remove_all(df$plain_text, "\\..*?\\{.*?\\}")

  # Initialize counters for removal reasons
  removal_reason_redirect <- sum(grepl("^(Redirect to:|Weiterleitung nach:|Rediriger vers:|Redirige a:|Přesměrování na:)", df$plain_text, ignore.case = TRUE))
  removal_reason_refering_page <- sum(grepl("may refer to:|ist der Name folgender Personen:|Cette page d'homonymie répertorie différentes personnes|může být:", df$plain_text, ignore.case = TRUE))
  removal_reason_not_found <- sum(grepl("^(Error fetching content for page:|No Wikipedia page name provided or missing|Es wurde kein Wikipedia-Seitenname angegeben)", df$plain_text, ignore.case = TRUE))
  
  
  # Filter rows based on specific conditions
  df <- df %>%
    filter(!grepl("^(Redirect to:|Weiterleitung nach:|Rediriger vers:|Redirige a:|Přesměrování na:)", plain_text, ignore.case = TRUE) &
             !grepl("may refer to:|ist der Name folgender Personen:|Cette page d'homonymie répertorie différentes personnes|může být:", plain_text, ignore.case = TRUE) &
             !grepl("Error fetching content for page:|No Wikipedia page name provided or missing|Es wurde kein Wikipedia-Seitenname angegeben", plain_text, ignore.case = TRUE))
  
  # Calculate the number of rows removed
  rows_removed <- initial_rows - nrow(df)
  
  # Print statistics about the removal reasons
  cat("Removal reasons:\n")
  cat("  - Redirect:", removal_reason_redirect, "\n")
  cat("  - Reference Page:", removal_reason_refering_page, "\n")
  cat("  - Not Found/no name_provided:", removal_reason_not_found, "\n")
  
  
  # Create a message about the cleaning process
  cat("Cleaned data: Removed", rows_removed, "rows.\n")
  
  # Return the cleaned data frame
  return(df)
}


deu <- clean_data(deu_text)
```


create a corpus 
```{r}
summary_df <- deu %>%
  group_by(sex) %>%
  summarise(text = paste(extracted_text, collapse = " ")) %>%
  ungroup()

deu <- deu[complete.cases(deu$sex), ]
deu$sex <- ifelse(deu$sex == "male", 0, 1)


# Erstellen des Corpus
corpus <- corpus(summary_df, docid_field = "sex")
```


Erstellen eines dfm 
```{r}

# Ersatzwörter-Vektor

# wörter die mit "in" enden prüfen auf genderte gruppen
# words_ending_in_in <- corpus_transposed %>%
#   filter(str_ends(word, "in")) %>%
#   pull(word)
# # 
# print(words_ending_in_in)
# 
# # wörter die mit "frau" enden prüfen auf genderte gruppen
# words_ending_in_frau <- corpus_transposed %>%
#   filter(str_ends(word, "frau")) %>%
#   pull(word)
# 
# print(words_ending_in_in)

gender_neutral_replacements <- c(
  "Politikerin" = "Politiker",
  "Lehrerin" = "Lehrer",
  "Sprecherin" = "Sprecher",
  "Wissenschaftlerin" = "Wissenschaftler",
  "Direktkandidatin" = "direktkandidat",
  "Staatssekretärin" = "Staatssekretär",
  "Mitarbeiterin" = "Mitarbeiter",
  "Leiterin" = "Leiter",
  "Geschäftsführerin" ="Geschäftsführer",
  "Referentin" ="referent",
  "Spitzenkandidatin" ="Spitzenkandidat",
  "Staatsministerin" = "Staatsminister",
  "Ministerin" ="Minister",
  "Rechtsanwältin" ="Rechtsanwalt",
  "Statträtin" = "Stadtrat",
  "Generalsekretärin" ="Generalsekretär",
  "Senatorin" = "Senator",
  "Richterin" ="Richter",
  "Assistentin" = "assistent",
  "Bürgermeisterin" = "Bürgermeister",
  "Präsidentin" = "Präsident",
  "Vizepräsidentin" = "Vizepräsident",
  "Obfrau" = "Obmann",
  "Kandidatin"= "Kandidat",
  "Anwältin" = "Anwalt",
  "Apothekerin"="Apotheker",
  "Betreuerin" ="Betreuer",
  "Betriebswirtin" = "Btriebswirtin",
  "Dezernentin" ="Dezernent",
  "Diplom-Volkswirtin" ="Diplom-Volkswirt",
  "Direktorin" = "Direktor",
  "Dozentin" = "Dozent",
  "Erzieherin"="Erzieher",
  "Fachärztin" = "Facharzt",
  "Familientherapeutin" ="Familientherapeut",
  "Fotografin"="Fotograf",
  "Gründerin"="Gründer",
  "Hauswirtschaftsleiterin"="Hasuwirtschaftsleiter",
  "Journalistin" = "Journalist",
  "Juristin" = "Jurist",
  "Köchin" ="Koch",
  "Korrespondentin" ="Korrespondent",
  "Krankenpflegerin" = "Krankenpfleger",
  "Kunsthistorikerin" = "Kunsthistoriker",
  "Landrätin" ="Landrat",
  "Lebensgefährtin" = "Lebensgefährt",
  "Nachfolgerin" = "Nachfolger",
  "Oberbürgermeisterin" = "oberbürgermeister",
  "Postbeamtin" = "Postbeamte",
  "Schauspielerin" = "Schauspieler",
  "Schneiderin" = "Schneider",
  "Schriftstellerin" = "Schriftsteller",
  "Sekretärin"="Sekretär",
  "Sprachlehrerin"="Sprachlehrer",
  "Stadträtin" ="Stadtrat",
  "Supervisorin"="Supervisor",
  "Unternehmerin"="Unternehmer",
  "Verkäuferin"="Verkäufer",
  "Wirtschaftsingenieurin" ="Wirtschaftsingenieur",
  "Ärztin"="Arzt",
  "Gräfin" ="graf",
  "Partnerin"="partner",
  "Bundeskanzlerin"="Bundeskanzler",
  "Betriebswirtin"="betriebswirt",
  "industriekauffrau"="Industriekaufmann",
  "Einzelhandelskauffrau"="Einzelhandelskaufmann",
  "bankkauffrau"="Bankkaufmann",
  "Autorin" = "autor",
  "Stenotypistin" = "stenotypist",
  "Pädagogin"="Padagoge",
  "Stellvertreterin" ="Stellvertreter",
  "Bundesministerin" = "bundesminister",
  "Biologin" = "Biologe",
  "Schülerin" = "Schüler",
  "Verlegerin" = "Verleger",
  "Btriebswirtin" = "Betriebswirt",
  "Staatsrätin" = "Staatsrat",
  "Fabrikarbeiterin" = "Fabrikarbeiter",
  "Steuerberaterin" = "Steuerberater",
  "Buchhalterin" = "Buchhalter",
  "Architektin" = "Architekt",
  "Justizsenatorin" = "Justizsenator",
  "Hauswirtschaftslehrerin" = "hauswirtschaftslehrer",
  "Gymnasiallehrerin" = "Gymnasiallehrer",
  "Sozialarbeiterin" ="Sozialarbeiter",
  "Studienrätin" = "Studienrat",
  "Diplom-Kauffrau" = "Diplom-Kaufmann",
  "Soldatin" = "Soldat",
  "Landwirtin" = "Landwirt",
  "Redakteurin" = "Redakteur",
  "Professorin" = "Professor",
  "Notarin" ="Notar",
  "Prokuristin" = "Prokurist",
  "Diplom-Igenieurin" = "Diplom-Ingenieur",
  "Gewerkschaftssekretärin" = "Gewerkschaftssekretär",
  "Nationalsozialistin" = "Nationalsozialist",
  "Chefredakteurin" = "Chefredakteur"
)

####ich möchte die namen aus der pmi analyse entfernen:
#namen extrahieren
first_words <- vapply(strsplit(matched_data$plain_text, "\\s+"), function(x) gsub("[,;:.!?]+$", "", x[1]), character(1))
second_words <- vapply(strsplit(matched_data$plain_text, "\\s+"), function(x) ifelse(length(x) > 1, gsub("[,;:.!?]+$", "", x[2]), ""), character(1))

##############namen problem
words_to_remove <- unique(c(first_words, second_words, stopwords("de")))

tokens <- tokens(corpus, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
  tokens_replace(pattern = names(gender_neutral_replacements), replacement = gender_neutral_replacements, case_insensitive = TRUE) %>%
  tokens_remove(pattern = words_to_remove, padding = FALSE) %>%
  tokens_wordstem(language = "german")

# Erstellen des DFM
dfmat <- tokens %>%
  dfm()

# Überprüfen Sie das Ergebnis
print(dfmat)

#covert to df
corpus_df <- convert(dfmat, to = "data.frame")

# Setzen der ersten Spalte als Zeilennamen
rownames(corpus_df) <- corpus_df[, 1]

# Entfernen der ersten Spalte aus dem DataFrame
corpus_df <- corpus_df[, -1]

#only keep words that appear in both genders
# Zählen der Nullen in jeder Spalte
zero_count_per_column <- colSums(corpus_df == 0)

# Filtern der Spalten, bei denen keine Nullen vorhanden sind
corpus_common <- corpus_df[, zero_count_per_column == 0]


#swap rows and columns
corpus_transposed <- t(corpus_common)

# Umwandeln der transponierten Matrix zurück in einen DataFrame
corpus_transposed <- as.data.frame(corpus_transposed)
corpus_transposed$word <- rownames(corpus_transposed)
rownames(corpus_transposed) <- NULL


```
Pmi Berechnung, top words
```{r}
# Berechnen der Gesamtanzahlen
total_male_count <- sum(corpus_transposed$male)
total_female_count <- sum(corpus_transposed$female)
total_count <- total_male_count + total_female_count

# Wahrscheinlichkeiten für jede Klasse
p_c_male <- total_male_count / total_count
p_c_female <- total_female_count / total_count

# Hinzufügen der PMI-Berechnungen zum DataFrame
pmi_df <- corpus_transposed %>%
  mutate(p_w = (male + female) / total_count,
         p_male_w = male / total_count,
         p_female_w = female / total_count,
         PMI_male = log(p_male_w / (p_w * p_c_male)) / -log(p_male_w),
         PMI_female = log(p_female_w / (p_w * p_c_female)) / -log(p_female_w))

min_p <- 0.01

# Filter the DataFrame for female PMI values
top_female <- pmi_df[pmi_df$PMI_female > min_p, ]
# Sort the filtered DataFrame by 'PMI_female' in descending order
top_female <- top_female[order(-top_female$PMI_female), ]
# Select the top 10 rows
top_female <- head(top_female, 100)

# Filter the DataFrame for male PMI values
top_male <- pmi_df[pmi_df$PMI_male > min_p, ]
# Sort the filtered DataFrame by 'PMI_male' in descending order
top_male <- top_male[order(-top_male$PMI_male), ]
# Select the top 10 rows
top_male <- head(top_male, 100)

# Print the top female PMI words
print("Top Female PMI Words:")
print(top_female)

print("Top male PMI Words:")
print(top_male)
```
Kategorien hinzufügen

F: Family
R: Relationship
G: Gender
O: Other
```{r}

#download data to annotate


#female data
write_csv(top_female, "female_pmi.csv")
female_pmi_cat <- read.csv("female_pmi_cat.csv", sep = ";")

female_pmi_cat %>%
  count(cat) %>%
  mutate(percentage = n / sum(n) * 100) %>%
  select(cat, percentage)


#male data
write_csv(top_male, "male_pmi.csv")
male_pmi_cat <- read.csv("male_pmi_cat.csv", sep = ";")

male_pmi_cat %>%
  count(cat) %>%
  mutate(percentage = n / sum(n) * 100) %>%
  select(cat, percentage)

m_count <- prop.table(table(male_pmi_cat$cat)) * 100
f_count <- prop.table(table(female_pmi_cat$cat)) * 100

# Initialisiere Vektoren für die Proportionen
m_proportions <- numeric(length = 4)
f_proportions <- numeric(length = 4)

categories <- c('F', 'G', 'O', 'R')

for (i in 1:4) {
  m_proportions[i] <- ifelse(categories[i] %in% names(m_count), m_count[categories[i]], 0)
  f_proportions[i] <- ifelse(categories[i] %in% names(f_count), f_count[categories[i]], 0)
}


###chi squared - categories with too low frequencies, not really reliable
chisq_result <- chisq.test(rbind(m_proportions, f_proportions))
print(chisq_result)

p0 <- as.numeric(m_proportions)
p1 <- as.numeric(f_proportions)

# Berechnung von Cohen's w in R
cohens_w <- sqrt(sum(((p1 - p0)^2) / p1))
print(cohens_w)

#fisher test which can be used exactly for those situatins with low frequencies
m_count_abs <- table(male_pmi_cat$cat)
f_count_abs <- table(female_pmi_cat$cat)

# Stelle sicher, dass beide Tabellen dieselben Kategorien in derselben Reihenfolge haben
all_categories <- union(names(m_count_abs), names(f_count_abs))
m_count_abs <- m_count_abs[all_categories]
f_count_abs <- f_count_abs[all_categories]

# Ersetze fehlende Kategorien durch 0
m_count_abs[is.na(m_count_abs)] <- 0
f_count_abs[is.na(f_count_abs)] <- 0

# Führe Fisher's Exact Test mit den absoluten Häufigkeiten durch
fisher_test_result <- fisher.test(rbind(m_count_abs, f_count_abs))
print(fisher_test_result)

###kleiner als 0.05 -> signifikant



```

visualization of results
```{r}

####mit ggwordcloud

library(ggwordcloud)


# Erstellen des Wordclouds mit ggwordcloud
female_wordcloud <- ggplot(female_pmi_cat, aes(label = word, size = female, colour = cat)) +
  geom_text_wordcloud() +
  scale_size_area(max_size = 15) + # Anpassen für bessere Visualisierung
  theme_minimal()

ggsave("visualisations/female_wordcloud.jpg", plot = female_wordcloud, width = 10, height = 8)

library(ggwordcloud)


# Erstellen des Wordclouds mit ggwordcloud
male_wordcloud <- ggplot(male_pmi_cat, aes(label = word, size = male, colour = cat)) +
  geom_text_wordcloud() +
  scale_size_area(max_size = 15) + # Anpassen für bessere Visualisierung
  theme_minimal()

ggsave("visualisations/male_wordcloud.jpg", plot = male_wordcloud, width = 10, height = 8)


```



matching preparation
```{r}
check_office <- function(wikidataid, offices_dataset) {
  # Extrahiere die Zeile für den gegebenen wikidataid
  office_row <- offices_dataset[offices_dataset$wikidataid == wikidataid, ]
  
  # Definiere die spezifischen Spalten, die geprüft werden sollen
  specific_columns <- c("bundesminister", "federal_chancellor_of_germany", 
                        "president_of_germany", "president_of_the_bundestag")
  
  # Füge zusätzlich alle Spalten hinzu, die mit "federal_minister" beginnen
  federal_minister_columns <- grep("^federal_minister", names(offices_dataset), value = TRUE)
  
  # Kombiniere alle relevanten Spalten
  relevant_columns <- c(specific_columns, federal_minister_columns)
  
  # Beachte, dass nur Spalten geprüft werden, die auch im DataFrame existieren
  relevant_columns <- relevant_columns[relevant_columns %in% names(office_row)]
  
  # Prüfe, ob in einer der relevanten Spalten TRUE steht
  # Stelle sicher, dass NA als FALSE behandelt wird
  any_true <- any(office_row[relevant_columns] == TRUE, na.rm = TRUE)
  
  # Wenn keine relevanten Spalten existieren oder alle FALSE sind, wird FALSE zurückgegeben
  return(ifelse(length(any_true) == 0, FALSE, any_true))
}

deu_offices <- get_office(legislature = "deu")

# Erstellen Sie eine neue Spalte im deu_text, die angibt, ob der Politiker ein Amt innehat
deu$important_office <- sapply(deu$wikidataid, check_office, offices_dataset = deu_offices)

deu_political$pageid <- as.integer(deu_political$pageid)
deu <- left_join(deu, select(deu_political, pageid, session, party, total_service), by = "pageid")
total_traffic_per_politician$pageid <- as.integer(total_traffic_per_politician$pageid)
deu <- left_join(deu, select(total_traffic_per_politician, pageid, total_traffic), by = "pageid")

```

```{r}
deu$birthyear <- substr(deu$birth, 1, 4)
deu$birthyear <- as.numeric(as.character(deu$birthyear))

deu <- deu[complete.cases(deu$sex), ]
deu$sex <- ifelse(deu$sex == "male", 0, 1)
missing_share <- colMeans(is.na(deu))
print(missing_share)

```








Match the data
```{r}
#propensity score matching

# match_obj <- matchit(sex ~ birthyear + session + total_service + total_traffic + party + important_office,
#                      data = deu, method = "nearest", distance ="glm",
#                      ratio = 1,
#                      replace = FALSE)
# 
# matched_data <- match.data(match_obj)

# wenn auf groups geamchted: 1946 obs.

# #coarsened matching
# 
# match_obj <- matchit(sex ~ birthyear + session + total_service + total_traffic + party + important_office,
#                      data = deu, method = "cem", replace = FALSE)
# 
# matched_data <- match.data(match_obj)


#pro session matchen (weil session eine hohe varianz hat nach dem matching)

#match data with propensity scores and include session as exact matching
match_obj <- matchit(sex ~ birthyear + total_service + total_traffic + party + important_office + session,
                     data = deu, method = "nearest", distance = "logit",
                     exact = "session", # Exaktes Matching auf 'session'
                     ratio = 1, replace = FALSE)

#get matched data
matched_data <- match.data(match_obj)


```



matching überprüfen
Std. mean difference: unter 0.1
Var. Ratio clode to 1
eCDF Mean and eCDF Max close to 0
```{r}
summary(match_obj)

```



create a corpus - matched data
```{r}
summary_df_matched <- matched_data %>%
  group_by(sex) %>%
  summarise(text = paste(extracted_text, collapse = " ")) %>%
  ungroup()%>%
  mutate(sex = ifelse(sex == 1, "female", "male"))


# Erstellen des Corpus
corpus_matched <- corpus(summary_df_matched, docid_field = "sex")
```


Erstellen eines dfm - matched data
```{r}

# Ersatzwörter-Vektor

# wörter die mit "in" enden prüfen auf genderte gruppen
# words_ending_in_in <- corpus_transposed %>%
#   filter(str_ends(word, "in")) %>%
#   pull(word)
# # 
# print(words_ending_in_in)
# 
# # wörter die mit "frau" enden prüfen auf genderte gruppen
# words_ending_in_frau <- corpus_transposed %>%
#   filter(str_ends(word, "frau")) %>%
#   pull(word)
# 
# print(words_ending_in_in)

gender_neutral_replacements <- c(
  "Politikerin" = "Politiker",
  "Lehrerin" = "Lehrer",
  "Sprecherin" = "Sprecher",
  "Wissenschaftlerin" = "Wissenschaftler",
  "Direktkandidatin" = "direktkandidat",
  "Staatssekretärin" = "Staatssekretär",
  "Mitarbeiterin" = "Mitarbeiter",
  "Leiterin" = "Leiter",
  "Geschäftsführerin" ="Geschäftsführer",
  "Referentin" ="referent",
  "Spitzenkandidatin" ="Spitzenkandidat",
  "Staatsministerin" = "Staatsminister",
  "Ministerin" ="Minister",
  "Rechtsanwältin" ="Rechtsanwalt",
  "Statträtin" = "Stadtrat",
  "Generalsekretärin" ="Generalsekretär",
  "Senatorin" = "Senator",
  "Richterin" ="Richter",
  "Assistentin" = "assistent",
  "Bürgermeisterin" = "Bürgermeister",
  "Präsidentin" = "Präsident",
  "Vizepräsidentin" = "Vizepräsident",
  "Obfrau" = "Obmann",
  "Kandidatin"= "Kandidat",
  "Anwältin" = "Anwalt",
  "Apothekerin"="Apotheker",
  "Betreuerin" ="Betreuer",
  "Betriebswirtin" = "Btriebswirtin",
  "Dezernentin" ="Dezernent",
  "Diplom-Volkswirtin" ="Diplom-Volkswirt",
  "Direktorin" = "Direktor",
  "Dozentin" = "Dozent",
  "Erzieherin"="Erzieher",
  "Fachärztin" = "Facharzt",
  "Familientherapeutin" ="Familientherapeut",
  "Fotografin"="Fotograf",
  "Gründerin"="Gründer",
  "Hauswirtschaftsleiterin"="Hasuwirtschaftsleiter",
  "Journalistin" = "Journalist",
  "Juristin" = "Jurist",
  "Köchin" ="Koch",
  "Korrespondentin" ="Korrespondent",
  "Krankenpflegerin" = "Krankenpfleger",
  "Kunsthistorikerin" = "Kunsthistoriker",
  "Landrätin" ="Landrat",
  "Lebensgefährtin" = "Lebensgefährt",
  "Nachfolgerin" = "Nachfolger",
  "Oberbürgermeisterin" = "oberbürgermeister",
  "Postbeamtin" = "Postbeamte",
  "Schauspielerin" = "Schauspieler",
  "Schneiderin" = "Schneider",
  "Schriftstellerin" = "Schriftsteller",
  "Sekretärin"="Sekretär",
  "Sprachlehrerin"="Sprachlehrer",
  "Stadträtin" ="Stadtrat",
  "Supervisorin"="Supervisor",
  "Unternehmerin"="Unternehmer",
  "Verkäuferin"="Verkäufer",
  "Wirtschaftsingenieurin" ="Wirtschaftsingenieur",
  "Ärztin"="Arzt",
  "Gräfin" ="graf",
  "Partnerin"="partner",
  "Bundeskanzlerin"="Bundeskanzler",
  "Betriebswirtin"="betriebswirt",
  "industriekauffrau"="Industriekaufmann",
  "Einzelhandelskauffrau"="Einzelhandelskaufmann",
  "bankkauffrau"="Bankkaufmann",
  "Autorin" = "autor",
  "Stenotypistin" = "stenotypist",
  "Pädagogin"="Padagoge",
  "Stellvertreterin" ="Stellvertreter",
  "Bundesministerin" = "bundesminister",
  "Biologin" = "Biologe",
  "Schülerin" = "Schüler",
  "Verlegerin" = "Verleger",
  "Btriebswirtin" = "Betriebswirt",
  "Staatsrätin" = "Staatsrat",
  "Fabrikarbeiterin" = "Fabrikarbeiter",
  "Steuerberaterin" = "Steuerberater",
  "Buchhalterin" = "Buchhalter",
  "Architektin" = "Architekt",
  "Justizsenatorin" = "Justizsenator",
  "Hauswirtschaftslehrerin" = "hauswirtschaftslehrer",
  "Gymnasiallehrerin" = "Gymnasiallehrer",
  "Sozialarbeiterin" ="Sozialarbeiter",
  "Studienrätin" = "Studienrat",
  "Diplom-Kauffrau" = "Diplom-Kaufmann",
  "Soldatin" = "Soldat",
  "Landwirtin" = "Landwirt",
  "Redakteurin" = "Redakteur",
  "Professorin" = "Professor",
  "Notarin" ="Notar",
  "Prokuristin" = "Prokurist",
  "Diplom-Igenieurin" = "Diplom-Ingenieur",
  "Gewerkschaftssekretärin" = "Gewerkschaftssekretär",
  "Nationalsozialistin" = "Nationalsozialist",
  "Chefredakteurin" = "Chefredakteur"
)

####ich möchte die namen aus der pmi analyse entfernen:
#namen extrahieren
first_words <- vapply(strsplit(matched_data$plain_text, "\\s+"), function(x) gsub("[,;:.!?]+$", "", x[1]), character(1))
second_words <- vapply(strsplit(matched_data$plain_text, "\\s+"), function(x) ifelse(length(x) > 1, gsub("[,;:.!?]+$", "", x[2]), ""), character(1))

##############namen problem
words_to_remove <- unique(c(first_words, second_words, stopwords("de")))

tokens_matched <- tokens(corpus_matched, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
  tokens_replace(pattern = names(gender_neutral_replacements), replacement = gender_neutral_replacements, case_insensitive = TRUE) %>%
  tokens_remove(pattern = words_to_remove, padding = FALSE) %>%
  tokens_wordstem(language = "german")

# Erstellen des DFM
dfmat_matched <- tokens_matched %>%
  dfm()

# Überprüfen Sie das Ergebnis
print(dfmat_matched)

#covert to df
corpus_df_matched <- convert(dfmat_matched, to = "data.frame")

# Setzen der ersten Spalte als Zeilennamen
rownames(corpus_df_matched) <- corpus_df_matched[, 1]

# Entfernen der ersten Spalte aus dem DataFrame
corpus_df_matched <- corpus_df_matched[, -1]

#only keep words that appear in both genders
# Zählen der Nullen in jeder Spalte
zero_count_per_column_matched <- colSums(corpus_df_matched == 0)

# Filtern der Spalten, bei denen keine Nullen vorhanden sind
corpus_common_matched <- corpus_df_matched[, zero_count_per_column_matched == 0]


#swap rows and columns
corpus_transposed_matched <- t(corpus_common_matched)

# Umwandeln der transponierten Matrix zurück in einen DataFrame
corpus_transposed_matched <- as.data.frame(corpus_transposed_matched)
corpus_transposed_matched$word <- rownames(corpus_transposed_matched)
rownames(corpus_transposed_matched) <- NULL


```
Pmi Berechnung, top words - matched data
```{r}
# Berechnen der Gesamtanzahlen
total_male_count_matched <- sum(corpus_transposed_matched$male)
total_female_count_matched <- sum(corpus_transposed_matched$female)
total_count_matched <- total_male_count_matched + total_female_count_matched

# Wahrscheinlichkeiten für jede Klasse
p_c_male_matched <- total_male_count_matched / total_count_matched
p_c_female_matched <- total_female_count_matched / total_count_matched

# Hinzufügen der PMI-Berechnungen zum DataFrame
pmi_df_matched <- corpus_transposed_matched %>%
  mutate(p_w = (male + female) / total_count_matched,
         p_male_w = male / total_count_matched,
         p_female_w = female / total_count_matched,
         PMI_male = log(p_male_w / (p_w * p_c_male_matched)) / -log(p_male_w),
         PMI_female = log(p_female_w / (p_w * p_c_female_matched)) / -log(p_female_w))

min_p <- 0.01

# Filter the DataFrame for female PMI values
top_female_matched <- pmi_df_matched[pmi_df_matched$PMI_female > min_p, ]
# Sort the filtered DataFrame by 'PMI_female' in descending order
top_female_matched <- top_female_matched[order(-top_female_matched$PMI_female), ]
# Select the top 10 rows
top_female_matched <- head(top_female_matched, 100)

# Filter the DataFrame for male PMI values
top_male_matched <- pmi_df_matched[pmi_df_matched$PMI_male > min_p, ]
# Sort the filtered DataFrame by 'PMI_male' in descending order
top_male_matched <- top_male_matched[order(-top_male_matched$PMI_male), ]
# Select the top 10 rows
top_male_matched <- head(top_male_matched, 100)

# Print the top female PMI words
print("Top Female PMI Words matched:")
print(top_female_matched)

print("Top male PMI Words matched:")
print(top_male_matched)
```

categories annotation
```{r}
#download data to annotate


#female data
write_csv(top_female_matched, "female_pmi_matched.csv")
female_pmi_cat_matched <- read.csv("female_pmi_cat_matched.csv", sep = ";")

female_pmi_cat_matched %>%
  count(cat) %>%
  mutate(percentage = n / sum(n) * 100) %>%
  select(cat, percentage)


#male data
write_csv(top_male_matched, "male_pmi_matched.csv")
male_pmi_cat_matched <- read.csv("male_pmi_cat_matched.csv", sep = ";")

male_pmi_cat_matched %>%
  count(cat) %>%
  mutate(percentage = n / sum(n) * 100) %>%
  select(cat, percentage)

m_count_matched <- prop.table(table(male_pmi_cat_matched$cat)) * 100
f_count_matched <- prop.table(table(female_pmi_cat_matched$cat)) * 100

m_proportions_matched <- numeric(length = 4)
f_proportions_matched <- numeric(length = 4)

categories <- c('F', 'G', 'O', 'R')

for (i in 1:4) {
  m_proportions_matched[i] <- ifelse(categories[i] %in% names(m_count_matched), m_count_matched[categories[i]], 0)
  f_proportions_matched[i] <- ifelse(categories[i] %in% names(f_count_matched), f_count_matched[categories[i]], 0)
}


###chi squared - categories with too low frequencies, not really reliable
chisq_result_matched <- chisq.test(rbind(m_proportions_matched, f_proportions_matched))
print(chisq_result)

p0_matched <- as.numeric(m_proportions_matched)
p1_matched <- as.numeric(f_proportions_matched)

# Berechnung von Cohen's w in R
cohens_w <- sqrt(sum(((p1_matched - p0_matched)^2) / p1_matched))
print(cohens_w_matched)

#fisher test which can be used exactly for those situatins with low frequencies
m_count_abs_matched <- table(male_pmi_cat_matched$cat)
f_count_abs_matched <- table(female_pmi_cat_matched$cat)

# Stelle sicher, dass beide Tabellen dieselben Kategorien in derselben Reihenfolge haben
all_categories <- union(names(m_count_abs), names(f_count_abs))
m_count_abs <- m_count_abs[all_categories]
f_count_abs <- f_count_abs[all_categories]

# Ersetze fehlende Kategorien durch 0
m_count_abs[is.na(m_count_abs)] <- 0
f_count_abs[is.na(f_count_abs)] <- 0

# Führe Fisher's Exact Test mit den absoluten Häufigkeiten durch
fisher_test_result <- fisher.test(rbind(m_count_abs, f_count_abs))
print(fisher_test_result)

###kleiner als 0.05 -> signifikant



```
visualization of results matched
```{r}

####mit ggwordcloud

library(ggwordcloud)


# Erstellen des Wordclouds mit ggwordcloud
female_wordcloud_matched <- ggplot(female_pmi_cat_matched, aes(label = word, size = female, colour = cat)) +
  geom_text_wordcloud() +
  scale_size_area(max_size = 15) + # Anpassen für bessere Visualisierung
  theme_minimal()

ggsave("visualisations/female_wordcloud_matched.jpg", plot = female_wordcloud_matched, width = 10, height = 8)

library(ggwordcloud)


# Erstellen des Wordclouds mit ggwordcloud
male_wordcloud_matched <- ggplot(male_pmi_cat, aes(label = word, size = male, colour = cat)) +
  geom_text_wordcloud() +
  scale_size_area(max_size = 15) + # Anpassen für bessere Visualisierung
  theme_minimal()

ggsave("visualisations/male_wordcloud_matched.jpg", plot = male_wordcloud_matched, width = 10, height = 8)


```


Alte Sessions vs neue Sessions

